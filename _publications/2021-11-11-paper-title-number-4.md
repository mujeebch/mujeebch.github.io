---
title: "Attack Rules: An Adversarial Approach to Generate Attacks for Industrial Control Systems using Machine Learning"
collection: publications
permalink: /publication/2021-11-11-paper-title-number-4
excerpt: 'Adversarial learning is used to test the robustness of machine learning algorithms under attack and create attacks that deceive the anomaly detection methods in Industrial Control System (ICS). Given that security assessment of an ICS demands that an exhaustive set of possible attack patterns is studied, in this work, we propose an association rule mining-based attack generation technique. The technique has been implemented using data from a Secure Water Treatment plant. The proposed technique was able to generate more than 110,000 attack patterns constituting a vast majority of new attack vectors which were not seen before. Automatically generated attacks improve our understanding of the potential attacks and enable the design of robust attack detection techniques.'
date: 2022-12-04
venue: 'IEEE GlobeCom 2022'
paperurl: 'https://ieeexplore.ieee.org/abstract/document/10001609'
citation: 'A. H. Khan, H. Ikram, C. M. Ahmed, N. U. Hassan and Z. A. Uzmi, "Energy Level Spoofing Attacks and Countermeasures in Blockchain-enabled IoT," GLOBECOM 2022 - 2022 IEEE Global Communications Conference, Rio de Janeiro, Brazil, 2022, pp. 4322-4327, doi: 10.1109/GLOBECOM48099.2022.10001609.'
---
Adversarial learning is used to test the robustness of machine learning algorithms under attack and create attacks that deceive the anomaly detection methods in Industrial Control System (ICS). Given that security assessment of an ICS demands that an exhaustive set of possible attack patterns is studied, in this work, we propose an association rule mining-based attack generation technique. The technique has been implemented using data from a Secure Water Treatment plant. The proposed technique was able to generate more than 110,000 attack patterns constituting a vast majority of new attack vectors which were not seen before. Automatically generated attacks improve our understanding of the potential attacks and enable the design of robust attack detection techniques.

